{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menú de Índice\n",
    "\n",
    "1. [Abre y examina el archivo de datos](#introduccion)\n",
    "2. [Abre y examina el archivo de datos](#abre-y-examina-el-archivo-de-datos)\n",
    "3. [Segmentación de datos](#segmenta)\n",
    "4. [Investiga la calidad de diferentes modelos cambiando los hiperparámetros](#calidad)\n",
    "5. [Evaluar el modelo usando el conjunto de prueba](#conjunto-de-prueba)\n",
    "6. [Prueba de cordura](#cordura)\n",
    "6. [Conclusión](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción <a id='introduccion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un mercado tan dinámico como el de las telecomunicaciones, la capacidad de adaptación y anticipación es fundamental para mantenerse relevante. En este sentido, la compañía móvil Megaline se enfrenta a un desafío significativo: la persistencia de clientes que aún utilizan planes heredados. Con el objetivo de optimizar su cartera de servicios y satisfacer las necesidades cambiantes de sus usuarios, Megaline busca desarrollar un modelo predictivo capaz de analizar el comportamiento de sus clientes y recomendar adecuadamente uno de sus nuevos planes: Smart o Ultra.\n",
    "\n",
    "A través de datos exhaustivos sobre el comportamiento de los suscriptores que ya han migrado a los planes nuevos, obtenidos previamente en el proyecto del sprint de Análisis Estadístico de Datos, se plantea la tarea de clasificación para crear un modelo efectivo que pueda seleccionar el plan más apropiado para cada cliente. Con el análisis previo de datos ya realizado, se abre la oportunidad de centrarse en la creación y evaluación de modelos, brindando a Megaline la posibilidad de tomar decisiones informadas y estratégicas para mejorar la experiencia del cliente y mantener su competitividad en el mercado móvil en constante evolución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importación de librerias e importación de datos<a id='abre-y-examina-el-archivo-de-datos'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo cargado exitosamente desde 'datasets/users_behavior.csv'\n"
     ]
    }
   ],
   "source": [
    "#->datos\n",
    "# Leer el archivo y almacenarlo en df\n",
    "def cargar_archivos_con_separadores(archivos_con_separadores):\n",
    "    \"\"\"\n",
    "    Carga múltiples archivos CSV con separadores específicos para cada archivo y los almacena en un diccionario de DataFrames.\n",
    "    \n",
    "    :param archivos_con_separadores: Diccionario donde las claves son los nombres de los archivos y los valores son los separadores.\n",
    "    :return: Diccionario con nombres de archivos como claves y DataFrames como valores.\n",
    "    \"\"\"\n",
    "    df = {}  # Objeto que almacenará los DataFrames\n",
    "\n",
    "    # Iterar sobre los archivos y sus separadores\n",
    "    for archivo_nombre, separador in archivos_con_separadores.items():\n",
    "        url_no_windows = '/datasets/' + archivo_nombre\n",
    "        url_windows = 'datasets/' + archivo_nombre\n",
    "        \n",
    "        try:\n",
    "            # Intentar cargar desde la ruta no-Windows\n",
    "            if os.path.exists(url_no_windows):\n",
    "                df[archivo_nombre] = pd.read_csv(url_no_windows, sep=separador, dtype={'votes': 'Int64'})\n",
    "                print(f\"Archivo cargado exitosamente desde '{url_no_windows}'\")\n",
    "            \n",
    "            # Intentar cargar desde la ruta Windows\n",
    "            elif os.path.exists(url_windows):\n",
    "                df[archivo_nombre] = pd.read_csv(url_windows, sep=separador, dtype={'votes': 'Int64'})\n",
    "                print(f\"Archivo cargado exitosamente desde '{url_windows}'\")\n",
    "            \n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Error: el archivo '{archivo_nombre}' no se encuentra en ninguna de las rutas especificadas.\")\n",
    "        \n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "        \n",
    "        except pd.errors.ParserError as e:\n",
    "            print(f\"Error al procesar el archivo CSV '{archivo_nombre}': {e}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Ha ocurrido un error inesperado con el archivo '{archivo_nombre}': {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Ejemplo de uso\n",
    "archivos_con_separadores = {\n",
    "    'users_behavior.csv': ',',    \n",
    "}\n",
    "\n",
    "# Cargar los archivos en el objeto df\n",
    "df_all = cargar_archivos_con_separadores(archivos_con_separadores)\n",
    "\n",
    "# El objeto df ahora contiene un DataFrame por cada archivo cargado\n",
    "df = df_all.get('users_behavior.csv')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Examinar los primeros registros del dataset\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segmentación de datos <a id='segmenta'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto de entrenamiento: (1285, 4)\n",
      "Dimensiones del conjunto de validación: (964, 4)\n",
      "Dimensiones del conjunto de prueba: (965, 4)\n"
     ]
    }
   ],
   "source": [
    "# < separa los datos en entrenamiento y validación >\n",
    "#df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Separar las características y la etiqueta\n",
    "X = df.drop('is_ultra', axis=1)  # Reemplaza 'plan' con el nombre de la columna de etiquetas si es diferente\n",
    "y = df['is_ultra']  # Reemplaza 'plan' con el nombre de la columna de etiquetas si es diferente\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento, validación y prueba\n",
    "#60% para el data set de entrenamiento\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.6, random_state=12345)\n",
    "# y del 40$ restante, 20% para validacion y 20% para prueba\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "\n",
    "print(f\"Dimensiones del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de validación: {X_valid.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Investigación de la calidad de diferentes modelos <a id='calidad'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad: 1, Precisión en validación: 0.7770\n",
      "Profundidad: 2, Precisión en validación: 0.7822\n",
      "Profundidad: 3, Precisión en validación: 0.8102\n",
      "Profundidad: 4, Precisión en validación: 0.8039\n",
      "Profundidad: 5, Precisión en validación: 0.7946\n",
      "Profundidad: 6, Precisión en validación: 0.8050\n",
      "Profundidad: 7, Precisión en validación: 0.7956\n",
      "Profundidad: 8, Precisión en validación: 0.8008\n",
      "Profundidad: 9, Precisión en validación: 0.7905\n",
      "Profundidad: 10, Precisión en validación: 0.7770\n",
      "Profundidad: 11, Precisión en validación: 0.7842\n",
      "Profundidad: 12, Precisión en validación: 0.7749\n",
      "Profundidad: 13, Precisión en validación: 0.7770\n",
      "Profundidad: 14, Precisión en validación: 0.7666\n",
      "Profundidad: 15, Precisión en validación: 0.7656\n",
      "Profundidad: 16, Precisión en validación: 0.7500\n",
      "Profundidad: 17, Precisión en validación: 0.7479\n",
      "Profundidad: 18, Precisión en validación: 0.7407\n",
      "Profundidad: 19, Precisión en validación: 0.7355\n",
      "Profundidad: 20, Precisión en validación: 0.7417\n",
      "\n",
      "Mejor profundidad: 3\n",
      "Mejor precisión en validación: 0.8102\n"
     ]
    }
   ],
   "source": [
    "mejor_precision = 0\n",
    "mejor_modelo = None\n",
    "mejor_profundidad = 0\n",
    "resultados = []\n",
    "\n",
    "# Probar diferentes profundidades de árbol de decisión\n",
    "for profundidad in range(1, 21):\n",
    "    modelo = DecisionTreeClassifier(max_depth=profundidad, random_state=12345)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    predicciones_valid = modelo.predict(X_valid)\n",
    "    precision_valid = accuracy_score(y_valid, predicciones_valid)\n",
    "    resultados.append((profundidad, precision_valid))\n",
    "    \n",
    "    if precision_valid > mejor_precision:\n",
    "        mejor_precision = precision_valid\n",
    "        mejor_modelo = modelo\n",
    "        mejor_profundidad = profundidad\n",
    "\n",
    "# Mostrar los resultados\n",
    "for profundidad, precision in resultados:\n",
    "    print(f\"Profundidad: {profundidad}, Precisión en validación: {precision:.4f}\")\n",
    "\n",
    "print(f\"\\nMejor profundidad: {mejor_profundidad}\")\n",
    "print(f\"Mejor precisión en validación: {mejor_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluar el modelo usando el conjunto de prueba <a id='conjunto-de-prueba'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.7772\n",
      "El modelo cumple con el umbral de exactitud.\n"
     ]
    }
   ],
   "source": [
    "# Predecir en el conjunto de prueba\n",
    "predicciones_test = mejor_modelo.predict(X_test)\n",
    "precision_test = accuracy_score(y_test, predicciones_test)\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba: {precision_test:.4f}\")\n",
    "\n",
    "# Verificar si la precisión cumple con el umbral\n",
    "umbral_exactitud = 0.75\n",
    "if precision_test >= umbral_exactitud:\n",
    "    print(\"El modelo cumple con el umbral de exactitud.\")\n",
    "else:\n",
    "    print(\"El modelo no cumple con el umbral de exactitud.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prueba de cordura <a id='cordura'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo trivial en el conjunto de prueba: 0.6984\n",
      "El modelo pasó la prueba de cordura y es mejor que un modelo trivial.\n"
     ]
    }
   ],
   "source": [
    "# se realiza una prueba de cordura comparando el modelo con un modelo trivial\n",
    "# para asegurarnos de que el modelo no está simplemente memorizando los datos de entrenamiento.\n",
    "# Modelo trivial (siempre predice la clase más frecuente)\n",
    "modelo_dummy = DummyClassifier(strategy=\"most_frequent\", random_state=12345)\n",
    "modelo_dummy.fit(X_train, y_train)\n",
    "predicciones = modelo_dummy.predict(X_test)\n",
    "precision_dummy = accuracy_score(y_test, predicciones)\n",
    "\n",
    "print(f\"Precisión del modelo trivial en el conjunto de prueba: {precision_dummy:.4f}\")\n",
    "\n",
    "# Comprobar que el modelo real tiene un mejor desempeño que el modelo trivial\n",
    "assert precision_test > precision_dummy, \"El modelo no está mejor que el modelo trivial\"\n",
    "print(\"El modelo pasó la prueba de cordura y es mejor que un modelo trivial.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusión <a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión\n",
    "Segmentación de datos: Dividimos los datos en conjuntos de entrenamiento, validación y prueba.\n",
    "Investigación de modelos: Probamos diferentes profundidades del árbol de decisiones y encontramos la mejor profundidad basada en la precisión del conjunto de validación.\n",
    "Evaluación del modelo: Evaluamos el modelo en el conjunto de prueba y verificamos que cumple con el umbral de precisión del 0.77.\n",
    "Prueba de cordura: Confirmamos que el modelo tiene un mejor desempeño que un modelo trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
